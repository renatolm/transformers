{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![OpenAI](img/openai.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arquitetura decoder-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pré-treinamento não supervisionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fine-tuning em tarefas de tradução, sumarização e Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolução dos modelos GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GPTs](img/gpts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GPT (2018)**: 117M de parâmetros, demonstrou a viabilidade desse tipo de modelo pré-treinado para executar tarefas genéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GPT-2 (2019)**: 1.5B de parâmetros, significativamente melhor, começou a levantar preocupações sobre o uso indevido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GPT-3 (2020)**: 175B de parâmetros, realiza diversas tarefas com precisão sem a necessidade de fine-tuning, começou a se tornar indistinguível de uma conversa com um humano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GPT-4 (2023)**: cerca de 1Tri de parâmetros..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **GPT-5 (2024)**: ???"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
